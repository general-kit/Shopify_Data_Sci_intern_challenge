{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Assumptions, data set is as is and does not have any issues\n",
      "#Issues such as formatting, lack of header and incorrect data types\n",
      "#all data in the imported set is valid for importation purposes\n",
      "#some tasks were performed outside of this python script, for information that was\n",
      "easily analysed from the google docs file, such as:\n",
      "#date range verification - all dates are in march of the same year,  ids\n",
      "\n",
      "This is the data set being used:\n",
      "       order_id  shop_id  user_id  order_amount  total_items payment_method  \\\n",
      "0            1       53      746           224            2           cash   \n",
      "1            2       92      925            90            1           cash   \n",
      "2            3       44      861           144            1           cash   \n",
      "3            4       18      935           156            1    credit_card   \n",
      "4            5       18      883           156            1    credit_card   \n",
      "...        ...      ...      ...           ...          ...            ...   \n",
      "4995      4996       73      993           330            2          debit   \n",
      "4996      4997       48      789           234            2           cash   \n",
      "4997      4998       56      867           351            3           cash   \n",
      "4998      4999       60      825           354            2    credit_card   \n",
      "4999      5000       44      734           288            2          debit   \n",
      "\n",
      "               created_at  \n",
      "0     2017-03-13 12:36:56  \n",
      "1     2017-03-03 17:38:52  \n",
      "2      2017-03-14 4:23:56  \n",
      "3     2017-03-26 12:43:37  \n",
      "4      2017-03-01 4:35:11  \n",
      "...                   ...  \n",
      "4995  2017-03-30 13:47:17  \n",
      "4996  2017-03-16 20:36:16  \n",
      "4997   2017-03-19 5:42:42  \n",
      "4998  2017-03-16 14:51:18  \n",
      "4999  2017-03-18 15:48:18  \n",
      "\n",
      "[5000 rows x 7 columns] \n",
      "\n",
      "\n",
      "#AOV(Average order Value) = Revenue / (Total number of orders (5000 orders in total))\n",
      "\n",
      "\n",
      "AOV = 3145.128\n",
      "\n",
      "#We know that there is an issue with the data (from the problem statement), so first thing to do is ensure the data is valid?\n",
      "#check the date range, make sure it only includes only data from March\n",
      "#run checks on the order number, price, starting with the unit price, as well as quantity of items ordered\n",
      "\n",
      "\n",
      "#To validate the order number, we will search and ensure that there are no duplicates\n",
      "\n",
      "\n",
      "There are not duplicates in the order_id\n",
      "\n",
      "#Given the statement that sneakers are affordable, assume that the unit cost of sneakers should be no more than $1000\n",
      "#according to  an article on statista.com published in Nov 2020, median cost of\n",
      "#average sneakers typically range between $70 and $250.\n",
      "\n",
      "\n",
      "#AOV of 3145 seems suspiciously high at a glance, so I will calculate the unit cost of each shoe sold by the stores\n",
      "#and add it to the data set\n",
      "\n",
      "This is the new data_set with the unit price of a shoe included\n",
      "       order_id  shop_id  user_id  order_amount  total_items payment_method  \\\n",
      "0            1       53      746           224            2           cash   \n",
      "1            2       92      925            90            1           cash   \n",
      "2            3       44      861           144            1           cash   \n",
      "3            4       18      935           156            1    credit_card   \n",
      "4            5       18      883           156            1    credit_card   \n",
      "...        ...      ...      ...           ...          ...            ...   \n",
      "4995      4996       73      993           330            2          debit   \n",
      "4996      4997       48      789           234            2           cash   \n",
      "4997      4998       56      867           351            3           cash   \n",
      "4998      4999       60      825           354            2    credit_card   \n",
      "4999      5000       44      734           288            2          debit   \n",
      "\n",
      "               created_at  unit_price  \n",
      "0     2017-03-13 12:36:56       112.0  \n",
      "1     2017-03-03 17:38:52        90.0  \n",
      "2      2017-03-14 4:23:56       144.0  \n",
      "3     2017-03-26 12:43:37       156.0  \n",
      "4      2017-03-01 4:35:11       156.0  \n",
      "...                   ...         ...  \n",
      "4995  2017-03-30 13:47:17       165.0  \n",
      "4996  2017-03-16 20:36:16       117.0  \n",
      "4997   2017-03-19 5:42:42       117.0  \n",
      "4998  2017-03-16 14:51:18       177.0  \n",
      "4999  2017-03-18 15:48:18       144.0  \n",
      "\n",
      "[5000 rows x 8 columns]\n",
      "\n",
      "Data set grouped by the unit price of a shoe, counting how many shop_ids match:\n",
      " unit_price\n",
      "90.0        42\n",
      "94.0        55\n",
      "101.0       42\n",
      "111.0       40\n",
      "112.0      124\n",
      "114.0       59\n",
      "116.0       58\n",
      "117.0       77\n",
      "118.0      118\n",
      "122.0       50\n",
      "127.0       52\n",
      "128.0       93\n",
      "129.0      142\n",
      "130.0      150\n",
      "131.0       97\n",
      "132.0       46\n",
      "133.0      151\n",
      "134.0       86\n",
      "136.0      105\n",
      "138.0       59\n",
      "140.0       55\n",
      "142.0      197\n",
      "144.0       39\n",
      "145.0       92\n",
      "146.0       89\n",
      "147.0       53\n",
      "148.0      101\n",
      "149.0       52\n",
      "153.0      256\n",
      "154.0       54\n",
      "155.0       42\n",
      "156.0      197\n",
      "158.0       94\n",
      "160.0      206\n",
      "161.0      101\n",
      "162.0       48\n",
      "163.0      122\n",
      "164.0      161\n",
      "165.0       58\n",
      "166.0       43\n",
      "168.0       39\n",
      "169.0       54\n",
      "171.0       48\n",
      "172.0       35\n",
      "173.0       99\n",
      "176.0      152\n",
      "177.0      148\n",
      "178.0      109\n",
      "181.0      112\n",
      "184.0       49\n",
      "187.0      105\n",
      "190.0       35\n",
      "193.0       44\n",
      "195.0       54\n",
      "196.0       61\n",
      "201.0       53\n",
      "352.0       51\n",
      "25725.0     46\n",
      "Name: shop_id, dtype: int64\n",
      "\n",
      "#From the data set grouped by unit price, it shows that the value 25725 appears to  be incorrect or a unique outlier\n",
      "#in the data set, which I will exclude for purposes of accuracy, given how large it is compared to the other values\n",
      "#remove where the unit_cost > 400\n",
      "#This step assumes that the value (unit cost 25725) is either incorrect - from a bug,\n",
      "#or incorrect data entry or a unique outlier\n",
      "#This high unit value would skew the results towards a higher AOV value, due to the high revenue\n",
      "\n",
      "\n",
      "This is the corrected dataset, after removing the purchaces\n",
      "      at unit cost is 25725\n",
      "       order_id  shop_id  user_id  order_amount  total_items payment_method  \\\n",
      "0            1       53      746           224            2           cash   \n",
      "1            2       92      925            90            1           cash   \n",
      "2            3       44      861           144            1           cash   \n",
      "3            4       18      935           156            1    credit_card   \n",
      "4            5       18      883           156            1    credit_card   \n",
      "...        ...      ...      ...           ...          ...            ...   \n",
      "4995      4996       73      993           330            2          debit   \n",
      "4996      4997       48      789           234            2           cash   \n",
      "4997      4998       56      867           351            3           cash   \n",
      "4998      4999       60      825           354            2    credit_card   \n",
      "4999      5000       44      734           288            2          debit   \n",
      "\n",
      "               created_at  unit_price  \n",
      "0     2017-03-13 12:36:56       112.0  \n",
      "1     2017-03-03 17:38:52        90.0  \n",
      "2      2017-03-14 4:23:56       144.0  \n",
      "3     2017-03-26 12:43:37       156.0  \n",
      "4      2017-03-01 4:35:11       156.0  \n",
      "...                   ...         ...  \n",
      "4995  2017-03-30 13:47:17       165.0  \n",
      "4996  2017-03-16 20:36:16       117.0  \n",
      "4997   2017-03-19 5:42:42       117.0  \n",
      "4998  2017-03-16 14:51:18       177.0  \n",
      "4999  2017-03-18 15:48:18       144.0  \n",
      "\n",
      "[4954 rows x 8 columns]\n",
      "\n",
      "Data set grouped by the total items, counting how many times the same number of items were purchased:\n",
      " total_items\n",
      "1       1830\n",
      "2       1832\n",
      "3        941\n",
      "4        293\n",
      "5         77\n",
      "6          9\n",
      "8          1\n",
      "2000      17\n",
      "Name: total_items, dtype: int64\n",
      "#Inspecting teh data further looking at the total_items column, one thing to notice is the total_items ordered from each shop\n",
      "#One shop ID 42, user ID 607, ordered 2000 items, which is significantly higher than\n",
      "#the other number of orders ranging from 1 - 8\n",
      "#Given that all these orders were from a single store, it could be that these orders were made\n",
      "#by a customer that regularly buys the same amount of shoes wholesale\n",
      "#thus using this customer to calculate the AOV or track the growth may skew the data (such as the modal value)\n",
      "#As such, I have decided to also exclude it from the data set.\n",
      "\n",
      "This is the corrected dataset, after removing the purchaces\n",
      "      at unit cost is 25725 as well as the order of 2000 items from user_id 602\n",
      "       order_id  shop_id  user_id  order_amount  total_items payment_method  \\\n",
      "0            1       53      746           224            2           cash   \n",
      "1            2       92      925            90            1           cash   \n",
      "2            3       44      861           144            1           cash   \n",
      "3            4       18      935           156            1    credit_card   \n",
      "4            5       18      883           156            1    credit_card   \n",
      "...        ...      ...      ...           ...          ...            ...   \n",
      "4995      4996       73      993           330            2          debit   \n",
      "4996      4997       48      789           234            2           cash   \n",
      "4997      4998       56      867           351            3           cash   \n",
      "4998      4999       60      825           354            2    credit_card   \n",
      "4999      5000       44      734           288            2          debit   \n",
      "\n",
      "               created_at  unit_price  \n",
      "0     2017-03-13 12:36:56       112.0  \n",
      "1     2017-03-03 17:38:52        90.0  \n",
      "2      2017-03-14 4:23:56       144.0  \n",
      "3     2017-03-26 12:43:37       156.0  \n",
      "4      2017-03-01 4:35:11       156.0  \n",
      "...                   ...         ...  \n",
      "4995  2017-03-30 13:47:17       165.0  \n",
      "4996  2017-03-16 20:36:16       117.0  \n",
      "4997   2017-03-19 5:42:42       117.0  \n",
      "4998  2017-03-16 14:51:18       177.0  \n",
      "4999  2017-03-18 15:48:18       144.0  \n",
      "\n",
      "[4937 rows x 8 columns]\n",
      "\n",
      "#The AOV can now be calculated with this \"incorrrect\" data excluded\n",
      "\n",
      "\n",
      "The new AOV after the data has been cleaned up is:\n",
      " 302.58051448247926\n",
      "#In summary, the issue with the data set appears to be abnormally high unit costs\n",
      "#as well as abnormally high orders from some shops\n",
      "\n",
      "NOTE: Below, is some analysis of the data sets at different levels show how the relationship between data changes as\n",
      "    the data is cleaned up\n",
      "\n",
      "\n",
      "The mean of the order amount and total item columns respectively from the original data is:\n",
      "Mean order amount:\n",
      "3145.128\n",
      "\n",
      "Mean total items ordered:\n",
      "8.7872\n",
      "\n",
      "\n",
      "The median of the order amount and total item columns respectively from the original data is:\n",
      "\n",
      "Median order amount:\n",
      "284.0\n",
      "\n",
      "Median total items ordered:\n",
      "2.0\n",
      "\n",
      "\n",
      "The mode of the order amount and total item columns respectively from the original data is:\n",
      "Mode order amount:\n",
      "153.0\n",
      "\n",
      "Mode total items ordered:\n",
      "2.0\n",
      "\n",
      "------------------------------ \n",
      "\n",
      "\n",
      "\n",
      "The mean of the order amount and total item columns respectively from the inital data correction\n",
      "(excluding only the high priced shoes of 25725 is:\n",
      "Mean order amount:\n",
      "2717.3677836092047\n",
      "\n",
      "Mean total items ordered:\n",
      "8.851029471134437\n",
      "\n",
      "\n",
      "The median of the order amount and total item columns respectively from the inital data correction\n",
      "(excluding only the high priced shoes of 25725 is:\n",
      "\n",
      "Median order amount:\n",
      "284.0\n",
      "\n",
      "Median total items ordered:\n",
      "2.0\n",
      "\n",
      "\n",
      "The mode of the order amount and total item columns respectively from the inital data correction\n",
      "(excluding only the high priced shoes of 25725 is:\n",
      "Mode order amount:\n",
      "153.0\n",
      "\n",
      "Mode total items ordered:\n",
      "2.0\n",
      "\n",
      "------------------------------ \n",
      "\n",
      "\n",
      "\n",
      "The mean of the order amount and total item columns respectively from the final data is:\n",
      "Mean order amount:\n",
      "302.58051448247926\n",
      "\n",
      "Mean total items ordered:\n",
      "1.9947336439133077\n",
      "\n",
      "\n",
      "The median of the order amount and total item columns respectively from the final data is:\n",
      "\n",
      "Median order amount:\n",
      "284.0\n",
      "\n",
      "Median total items ordered:\n",
      "2.0\n",
      "\n",
      "\n",
      "The mode of the order amount and total item columns respectively from the final data is:\n",
      "Mode order amount:\n",
      "153.0\n",
      "\n",
      "Mode total items ordered:\n",
      "2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"\"\"#Assumptions, data set is as is and does not have any issues\n",
    "#Issues such as formatting, lack of header and incorrect data types\n",
    "#all data in the imported set is valid for importation purposes\n",
    "#some tasks were performed outside of this python script, for information that was\n",
    "easily analysed from the google docs file, such as:\n",
    "#date range verification - all dates are in march of the same year,  ids\\n\"\"\")\n",
    "\n",
    "#define the list of the dataset from the google docs file\n",
    "data_source = \"https://docs.google.com/spreadsheets/d/16i38oonuX1y1g7C_UAmiK9GkY7cS-64DfiDMNiR41LM/export?format=csv&gid=0\"\n",
    "\n",
    "#import data as a csv\n",
    "data_set = pd.read_csv(data_source)\n",
    "print(\"This is the data set being used:\\n\", data_set, \"\\n\")\n",
    "\n",
    "#get the number of rows\n",
    "Num_Rows = len(data_set)\n",
    "\n",
    "#given the somewhat large data set, convert from a dictionary to data frame ?\n",
    "data_set = pd.DataFrame(data_set)\n",
    "\n",
    "#verify headers\n",
    "#verify no data in headers?\n",
    "#if {\n",
    "#len(data_set.head(0))  == 0\n",
    "#}\n",
    "\n",
    "print(\"\\n#AOV(Average order Value) = Revenue / (Total number of orders (5000 orders in total))\\n\")\n",
    "AOV = (sum(data_set.iloc[:,3])) / len(data_set)\n",
    "print(\"\\nAOV =\", AOV)\n",
    "\n",
    "print(\"\"\"\\n#We know that there is an issue with the data (from the problem statement), so first thing to do is ensure the data is valid?\n",
    "#check the date range, make sure it only includes only data from March\n",
    "#run checks on the order number, price, starting with the unit price, as well as quantity of items ordered\\n\"\"\")\n",
    "\n",
    "print(\"\"\"\\n#To validate the order number, we will search and ensure that there are no duplicates\\n\"\"\")\n",
    "val_order_id_set = set(data_set.order_id)\n",
    "\n",
    "if len(val_order_id_set) != len(data_set.order_id):\n",
    "    print(\"\\nDuplicates exist\\n\")\n",
    "else: print(\"\\nThere are not duplicates in the order_id\\n\")\n",
    "\n",
    "\n",
    "print(\"\"\"#Given the statement that sneakers are affordable, assume that the unit cost of sneakers should be no more than $1000\n",
    "#according to  an article on statista.com published in Nov 2020, median cost of\n",
    "#average sneakers typically range between $70 and $250.\n",
    "\n",
    "\n",
    "#AOV of 3145 seems suspiciously high at a glance, so I will calculate the unit cost of each shoe sold by the stores\n",
    "#and add it to the data set\"\"\")\n",
    "\n",
    "unit_price = data_set.iloc[:,3]/data_set.iloc[:,4]\n",
    "\n",
    "#update the data set to include the unit_cost\n",
    "data_set['unit_price'] = unit_price\n",
    "print(\"\\nThis is the new data_set with the unit price of a shoe included\\n\",data_set)\n",
    "\n",
    "#group the date by the number of times a particular unit cost appears\n",
    "unit_price_grouped = data_set.groupby(\"unit_price\")[\"shop_id\"].count()\n",
    "print(\"\\nData set grouped by the unit price of a shoe, counting how many shop_ids match:\\n\",unit_price_grouped)\n",
    "\n",
    "print(\"\"\"\\n#From the data set grouped by unit price, it shows that the value 25725 appears to  be incorrect or a unique outlier\n",
    "#in the data set, which I will exclude for purposes of accuracy, given how large it is compared to the other values\n",
    "#remove where the unit_cost > 400\n",
    "#This step assumes that the value (unit cost 25725) is either incorrect - from a bug,\n",
    "#or incorrect data entry or a unique outlier\n",
    "#This high unit value would skew the results towards a higher AOV value, due to the high revenue\\n\"\"\")\n",
    "\n",
    "data_set_corrected = data_set.loc[data_set.unit_price < 400]\n",
    "print(\"\"\"\\nThis is the corrected dataset, after removing the purchaces\n",
    "      at unit cost is 25725\\n\"\"\",data_set_corrected)\n",
    "\n",
    "\n",
    "\n",
    "total_items_grouped = data_set.groupby(\"total_items\")[\"total_items\"].count()\n",
    "print(\"\\nData set grouped by the total items, counting how many times the same number of items were purchased:\\n\",total_items_grouped)\n",
    "      \n",
    "print(\"\"\"#Inspecting teh data further looking at the total_items column, one thing to notice is the total_items ordered from each shop\n",
    "#One shop ID 42, user ID 607, ordered 2000 items, which is significantly higher than\n",
    "#the other number of orders ranging from 1 - 8\n",
    "#Given that all these orders were from a single store, it could be that these orders were made\n",
    "#by a customer that regularly buys the same amount of shoes wholesale\n",
    "#thus using this customer to calculate the AOV or track the growth may skew the data (such as the modal value)\n",
    "#As such, I have decided to also exclude it from the data set.\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "data_set_corrected2 = data_set_corrected.loc[data_set_corrected.total_items < 2000]\n",
    "\n",
    "print(\"\"\"\\nThis is the corrected dataset, after removing the purchaces\n",
    "      at unit cost is 25725 as well as the order of 2000 items from user_id 602\\n\"\"\",data_set_corrected2)\n",
    "\n",
    "#recalculate the AOV\n",
    "print(\"\"\"\\n#The AOV can now be calculated with this \"incorrrect\" data excluded\\n\"\"\")\n",
    "\n",
    "AOV_corrected2 = (sum(data_set_corrected2.iloc[:,3])) / len(data_set_corrected2)\n",
    "\n",
    "print(\"\"\"\\nThe new AOV after the data has been cleaned up is:\\n\"\"\", AOV_corrected2)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\"\"#In summary, the issue with the data set appears to be abnormally high unit costs\n",
    "#as well as abnormally high orders from some shops\"\"\")\n",
    "\n",
    "print(\"\"\"\\nNOTE: Below, is some analysis of the data sets at different levels show how the relationship between data changes as\n",
    "    the data is cleaned up\\n\"\"\")\n",
    "mean_data_set = data_set.mean(axis = 0)\n",
    "median_data_set = data_set.median()\n",
    "mode_data_set = data_set.mode()\n",
    "\n",
    "print(f\"\"\"\\nThe mean of the order amount and total item columns respectively from the original data is:\n",
    "Mean order amount:\\n{mean_data_set.order_amount}\n",
    "\\nMean total items ordered:\\n{mean_data_set.total_items}\\n\"\"\")\n",
    "\n",
    "print(f\"\"\"\\nThe median of the order amount and total item columns respectively from the original data is:\n",
    "\\nMedian order amount:\\n{median_data_set.order_amount}\n",
    "\\nMedian total items ordered:\\n{median_data_set.total_items}\\n\"\"\")\n",
    "\n",
    "print(f\"\"\"\\nThe mode of the order amount and total item columns respectively from the original data is:\n",
    "Mode order amount:\\n{mode_data_set.order_amount[0]}\n",
    "\\nMode total items ordered:\\n{mode_data_set.total_items[0]}\\n\"\"\")\n",
    "\n",
    "print('-'*30,'\\n'*2)\n",
    "mean_data_set_corrected = data_set_corrected.mean(axis = 0)\n",
    "median_data_set_corrected = data_set_corrected.median(axis = 0)\n",
    "mode_data_set_corrected = data_set_corrected.mode(axis = 0)\n",
    "\n",
    "print(f\"\"\"\\nThe mean of the order amount and total item columns respectively from the inital data correction\n",
    "(excluding only the high priced shoes of 25725 is:\n",
    "Mean order amount:\\n{mean_data_set_corrected.order_amount}\n",
    "\\nMean total items ordered:\\n{mean_data_set_corrected.total_items}\\n\"\"\")\n",
    "\n",
    "print(f\"\"\"\\nThe median of the order amount and total item columns respectively from the inital data correction\n",
    "(excluding only the high priced shoes of 25725 is:\n",
    "\\nMedian order amount:\\n{median_data_set_corrected.order_amount}\n",
    "\\nMedian total items ordered:\\n{median_data_set_corrected.total_items}\\n\"\"\")\n",
    "\n",
    "print(f\"\"\"\\nThe mode of the order amount and total item columns respectively from the inital data correction\n",
    "(excluding only the high priced shoes of 25725 is:\n",
    "Mode order amount:\\n{mode_data_set_corrected.order_amount[0]}\n",
    "\\nMode total items ordered:\\n{mode_data_set_corrected.total_items[0]}\\n\"\"\")\n",
    "\n",
    "print('-'*30,'\\n'*2)\n",
    "mean_data_set_corrected2 = data_set_corrected2.mean(axis = 0)\n",
    "median_data_set_corrected2 = data_set_corrected2.median(axis = 0)\n",
    "mode_data_set_corrected2 = data_set_corrected2.mode()\n",
    "\n",
    "print(f\"\"\"\\nThe mean of the order amount and total item columns respectively from the final data is:\n",
    "Mean order amount:\\n{mean_data_set_corrected2.order_amount}\n",
    "\\nMean total items ordered:\\n{mean_data_set_corrected2.total_items}\\n\"\"\")\n",
    "\n",
    "print(f\"\"\"\\nThe median of the order amount and total item columns respectively from the final data is:\n",
    "\\nMedian order amount:\\n{median_data_set_corrected2.order_amount}\n",
    "\\nMedian total items ordered:\\n{median_data_set_corrected2.total_items}\\n\"\"\")\n",
    "\n",
    "print(f\"\"\"\\nThe mode of the order amount and total item columns respectively from the final data is:\n",
    "Mode order amount:\\n{mode_data_set_corrected2.order_amount[0]}\n",
    "\\nMode total items ordered:\\n{mode_data_set_corrected2.total_items[0]}\\n\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
